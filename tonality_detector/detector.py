from dostoevsky.tokenization import RegexTokenizer
from dostoevsky.models import FastTextSocialNetworkModel

test = [
    '''Ужасное расположение и распределение товаров. Два уровня и на каждом свои кассы. '
    'Чтобы купить разные группы товаров нужно отстоять две очереди.''',
    '''Это не шаурма это ужас,куча майонеза,лук одна кожура верхний слой который мы '
    'при готовке выкладываем,картофель фри из пачек сухой, мясо порезано тонкими '
    'пластами, не пойму как оно приготавливалось явно не на гриле, мясо было не свежее, '
    'в итоге самый съедобный оказался лаваш, не рекомендую.''',
    '''Рядом с домом, вкусная картошечка и обалденные молочные коктейли и '
    'довольно быстрое обслуживание, приятные кассиры''',
    '''Замечательный телефон, пользуюсь им уже 2 года, очень нравится!''']

tokenizer = RegexTokenizer()
model = FastTextSocialNetworkModel(tokenizer=tokenizer)

results = model.predict(test, k=1)
for token, sentiment in zip(test, results):
    print(sentiment.keys())








